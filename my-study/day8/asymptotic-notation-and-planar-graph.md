# 渐近符号与平面图复杂度分析

> 本文深入解析 Knuth 引入的渐近记法体系，并详细推导平面图中顶点、边、面数量的同阶关系。

---

## 一、Knuth 与渐近符号的历史

**Donald Knuth**（高德纳）是计算机科学的巨擘，他在经典著作《计算机程序设计艺术》中系统化了渐近符号的使用，使其成为算法分析的标准语言。

这套记法借鉴了数学分析中的极限论，但更适合描述算法的"增长趋势"而非精确值。

---

## 二、四种渐近符号的精确定义

### 2.1 大O记法：O(g(n)) —— 渐近上界

**定义**：
$$
f(n) = O(g(n)) \iff \exists C_1 > 0, \exists N_0 > 0: \forall n > N_0, |f(n)| \leq C_1 \cdot g(n)
$$

**直观理解**：
- f(n) 的增长速度**不超过** g(n)
- 存在一个"天花板" C₁·g(n)，当 n 足够大时，f(n) 永远在其下方

**极限形式**：
$$
f(n) = O(g(n)) \iff \limsup_{n \to \infty} \frac{|f(n)|}{g(n)} < \infty
$$

---

### 2.2 大Ω记法：Ω(g(n)) —— 渐近下界

**定义**：
$$
f(n) = \Omega(g(n)) \iff \exists C_1 > 0, \exists N_0 > 0: \forall n > N_0, f(n) \geq C_1 \cdot |g(n)|
$$

**直观理解**：
- f(n) 的增长速度**不低于** g(n)
- 存在一个"地板" C₁·g(n)，当 n 足够大时，f(n) 永远在其上方

**极限形式**：
$$
f(n) = \Omega(g(n)) \iff \liminf_{n \to \infty} \frac{|f(n)|}{g(n)} > 0
$$

---

### 2.3 大Θ记法：Θ(g(n)) —— 渐近紧界（同阶）

**定义**：
$$
f(n) = \Theta(g(n)) \iff \exists C_1, C_2 > 0, \exists N_0 > 0: \forall n > N_0, C_1 \cdot g(n) \leq f(n) \leq C_2 \cdot g(n)
$$

**等价表述**：
$$
f(n) = \Theta(g(n)) \iff f(n) = O(g(n)) \text{ 且 } f(n) = \Omega(g(n))
$$

**直观理解**：
- f(n) 和 g(n) **同阶**：它们的增长速度相同（仅相差常数倍）
- f(n) 被夹在两个常数倍的 g(n) 之间

**极限形式**：
$$
f(n) = \Theta(g(n)) \iff 0 < \lim_{n \to \infty} \frac{f(n)}{g(n)} < \infty
$$

---

### 2.4 小o记法：o(g(n)) —— 严格上界（低阶）

**定义**：
$$
f(n) = o(g(n)) \iff \forall C_1 > 0, \exists N_0 > 0: \forall n > N_0, |f(n)| < C_1 \cdot g(n)
$$

**关键区别**：
- 大O：**存在**某个常数 C₁ 使不等式成立
- 小o：对**任意**正数 C₁ 都存在 N₀ 使不等式成立

**直观理解**：
- f(n) 增长**严格慢于** g(n)
- f(n) 相对于 g(n) 可以忽略不计

**极限形式（最重要！）**：
$$
f(n) = o(g(n)) \iff \lim_{n \to \infty} \frac{f(n)}{g(n)} = 0
$$

**示例**：
- n = o(n²)，因为 lim(n/n²) = lim(1/n) = 0
- log n = o(n)，因为 lim(log n / n) = 0
- n² ≠ o(n²)，因为 lim(n²/n²) = 1 ≠ 0

---

## 三、符号关系总结

```
         增长速度比较

f(n) = o(g(n))     f 严格慢于 g     lim f/g = 0
         ↓
f(n) = O(g(n))     f 不快于 g       lim sup f/g < ∞
         ↓
f(n) = Θ(g(n))     f 与 g 同阶     0 < lim f/g < ∞
         ↑
f(n) = Ω(g(n))     f 不慢于 g       lim inf f/g > 0
         ↑
f(n) = ω(g(n))     f 严格快于 g     lim f/g = ∞
```

**重要关系**：
- Θ(g) = O(g) ∩ Ω(g)
- o(g) ⊂ O(g)（小o是大O的真子集）
- f = Θ(g) ⟺ g = Θ(f)（同阶关系是对称的）

---

## 四、平面图中的应用：式(1.5)的推导

### 4.1 问题背景

对于一个**简单连通平面图**，设：
- v = 顶点数（vertices）
- e = 边数（edges）
- f = 面数（faces，包括无界外部面）

**欧拉公式**：
$$
v - e + f = 2
$$

### 4.2 约束条件

如果平面图满足：
1. **每个顶点的度数至少为 3**（每个顶点连接至少3条边）
2. **每个面至少由 3 条边围成**（三角形或更多边的多边形）

### 4.3 关键不等式推导

**从条件1推导**：

#### 第一步：握手定理（Handshaking Lemma）

握手定理告诉我们，所有顶点度数之和等于边数的2倍：

$$
\sum_{v} \deg(v) = 2e
$$

**为什么？** 每条边有两个端点，所以：

- 一条边对"度数总和"贡献2（两端各贡献1）
- 因此所有顶点的度数之和 = 2 × 边数

**举例**：一个三角形

```text
    A
   / \
  /   \
 B-----C

deg(A) = 2, deg(B) = 2, deg(C) = 2
度数和 = 2 + 2 + 2 = 6 = 2 × 3条边 ✓
```

#### 第二步：应用度数约束

**条件**：每个顶点的度数至少为3（deg(v) ≥ 3）

$$
\sum_{v} \deg(v) \geq 3 \times (\text{顶点个数}) = 3v
$$

**结合握手定理**：

$$
2e = \sum \deg(v) \geq 3v
$$

#### 第三步：代数变换

从 2e ≥ 3v 可以推导出两个有用的不等式：

$$
\text{两边除以2:} \quad e \geq \frac{3v}{2} \quad \text{（边数至少是顶点数的1.5倍）}
$$

$$
\text{两边除以3:} \quad v \leq \frac{2e}{3} \quad \text{（顶点数最多是边数的2/3）}
$$

#### 直观理解

| 关系式 | 含义 |
| ------ | ---- |
| e ≥ 3v/2 | 边数**下界**：边至少是顶点的1.5倍 |
| v ≤ 2e/3 | 顶点数**上界**：顶点最多是边的2/3 |

**为什么有这个关系？** 因为每个顶点至少连3条边，但每条边被两个顶点共享，所以边必须足够多才能"供养"这么多顶点。

#### 具体例子：正四面体

正四面体是最简单的满足条件的图：

```text
      A
     /|\
    / | \
   /  |  \
  B---+---C
   \  |  /
    \ | /
     \|/
      D

v = 4 顶点
e = 6 边
每个顶点度数 = 3 ✓

验证: e = 6 ≥ 3×4/2 = 6 ✓
验证: v = 4 ≤ 2×6/3 = 4 ✓
（正四面体恰好取到等号！）
```

---

**从条件2推导**：

每个面由至少3条边围成，而每条边最多属于2个面（边的两侧各一个面）：

$$
\sum_{f} (\text{围成面的边数}) \geq 3f
$$

$$
2e \geq 3f
$$

因此：

$$
f \leq \frac{2e}{3}
$$

### 4.4 结合欧拉公式

从欧拉公式 v - e + f = 2：
$$
f = 2 - v + e
$$

代入 f ≤ 2e/3：
$$
2 - v + e \leq \frac{2e}{3}
$$
$$
e - v \leq \frac{2e}{3} - 2
$$
$$
\frac{e}{3} \leq v - 2
$$
$$
e \leq 3v - 6
$$

因此：

$$
e \leq 3v - 6 \quad \text{（e关于v的上界）}
$$

#### 推导 f 关于 e 的下界：f ≥ e/3 + 2

从欧拉公式：

$$
f = 2 - v + e
$$

利用顶点约束 v ≤ 2e/3（即 -v ≥ -2e/3）：

$$
f = 2 - v + e \geq 2 - \frac{2e}{3} + e = 2 + \frac{e}{3}
$$

因此：

$$
f \geq \frac{e}{3} + 2 \quad \text{（f关于e的下界）}
$$

#### 推导 f 关于 v 的上界：f ≤ 2v - 4

方法：将 e ≤ 3v - 6 代入 f ≤ 2e/3

$$
f \leq \frac{2e}{3} \leq \frac{2(3v - 6)}{3} = 2v - 4
$$

因此：

$$
f \leq 2v - 4 \quad \text{（f关于v的上界）}
$$

#### 推导 f 关于 v 的下界：f ≥ v/2

方法：将 e ≥ 3v/2 代入 f ≥ e/3 + 2

$$
f \geq \frac{e}{3} + 2 \geq \frac{3v/2}{3} + 2 = \frac{v}{2} + 2 \geq \frac{v}{2}
$$

因此：

$$
f \geq \frac{v}{2} \quad \text{（f关于v的下界）}
$$

---

### 4.5 完整结论

#### 所有界的推导汇总

**1. e 与 v 的关系**

| 界 | 公式 | 推导来源 |
| ---- | ---- | ---- |
| 下界 | e ≥ 3v/2 | 度数约束：2e ≥ 3v |
| 上界 | e ≤ 3v - 6 | 欧拉公式 + 面约束：f = 2-v+e 代入 f ≤ 2e/3 |

**2. f 与 e 的关系**

| 界 | 公式 | 推导来源 |
| ---- | ---- | ---- |
| 上界 | f ≤ 2e/3 | 面约束：2e ≥ 3f |
| 下界 | f ≥ e/3 + 2 | 欧拉公式 + 顶点约束：f = 2-v+e 且 v ≤ 2e/3 |

**3. f 与 v 的关系**

| 界 | 公式 | 推导来源 |
| ---- | ---- | ---- |
| 上界 | f ≤ 2v - 4 | 传递：f ≤ 2e/3 且 e ≤ 3v-6 |
| 下界 | f ≥ v/2 | 传递：f ≥ e/3+2 且 e ≥ 3v/2 |

#### 完整结论表格

对于满足上述条件的平面图：

| 关系 | 上界 | 下界 | 结论 |
| ---- | ---- | ---- | ---- |
| e 与 v | e ≤ 3v - 6 | e ≥ 3v/2 | e = Θ(v) |
| f 与 e | f ≤ 2e/3 | f ≥ e/3 + 2 | f = Θ(e) |
| f 与 v | f ≤ 2v - 4 | f ≥ v/2 | f = Θ(v) |

#### 为什么有上下界就能得出 Θ？

以 **e 与 v** 为例：

```text
下界: e ≥ 3v/2 = 1.5v    →  e = Ω(v)  （e不慢于v）
上界: e ≤ 3v - 6 ≈ 3v    →  e = O(v)  （e不快于v）

合起来: Ω(v) ∩ O(v) = Θ(v)  （e与v同阶）
```

**关键洞察**：上界和下界都是 v 的**线性函数**（常数倍），所以 e 和 v 同阶！

**式(1.5)的完整表述**：
$$
f = O(v), \quad e = O(v), \quad v = O(f), \quad e = O(f), \quad f = O(e), \quad v = O(e)
$$

**等价于**：
$$
v = \Theta(e) = \Theta(f)
$$

即：**顶点数、边数、面数三者两两同阶！**

---

## 五、对网格生成的意义

### 5.1 为什么这个结论重要？

在网格生成（如 Gmsh）中：
- **v** = 网格节点数
- **e** = 网格边数
- **f** = 网格单元数（2D三角形或四边形）

式(1.5)告诉我们：**这三个量是同阶的**！

### 5.2 算法复杂度分析

假设一个网格算法的复杂度是 O(v + e + f)，由于三者同阶：
$$
O(v + e + f) = O(v) = O(e) = O(f)
$$

这意味着：
- 用顶点数描述复杂度和用边数/面数描述是等价的
- 网格规模翻倍，所有三个量都翻倍

### 5.3 内存估算

如果每个顶点需要存储坐标（3个浮点数），每条边存储端点索引（2个整数），每个三角形存储顶点索引（3个整数）：

总内存 = 3v·sizeof(double) + 2e·sizeof(int) + 3f·sizeof(int)

由于 v ≈ e ≈ f（同阶），可以简化为：
$$
\text{内存} = \Theta(v) = \Theta(n)
$$

其中 n 是任意一个量。

---

## 六、总结

### 核心要点

1. **四种渐近符号**刻画了函数增长速度的不同关系：
   - O：上界（不超过）
   - Ω：下界（不低于）
   - Θ：紧界（同阶）
   - o：严格上界（严格慢于）

2. **小o与极限的等价性**是理解这些符号的关键：
   $$f = o(g) \iff \lim \frac{f}{g} = 0$$

3. **平面图中 v、e、f 同阶**是一个深刻的拓扑结论，对网格生成算法分析具有重要意义。

### 记忆口诀

```
大O是上界，最多这么大；
大Ω是下界，至少这么快；
大Θ是紧界，上下都有框；
小o最严格，极限趋于零。
```

---

## 七、排序时间复杂度的下界（决策树证明）

> 本节介绍如何用决策树模型证明：**比较排序算法的时间复杂度不可能低于 O(n log n)**

### 7.1 问题引入

我们知道很多经典排序算法：

| 算法 | 平均时间复杂度 | 最坏时间复杂度 |
| ---- | ---- | ---- |
| 冒泡排序 | O(n²) | O(n²) |
| 快速排序 | O(n log n) | O(n²) |
| 归并排序 | O(n log n) | O(n log n) |
| 堆排序 | O(n log n) | O(n log n) |

**核心问题**：能设计出比 O(n log n) 更快的比较排序算法吗？

**答案**：**不能！** O(n log n) 是比较排序的**理论下界**。

### 7.2 决策树模型

**什么是决策树？**

决策树是一种用**二叉树**表示排序算法执行过程的模型：

- **内部节点**：一次比较操作（如 "a₁ ≤ a₂?"）
- **左子树**：比较结果为"是"时的后续操作
- **右子树**：比较结果为"否"时的后续操作
- **叶节点**：最终的排序结果（一种排列）

**示例：3个数 {a₁, a₂, a₃} 的决策树**

```text
                    a₁ ≤ a₂?
                   /        \
                 是          否
                /              \
           a₂ ≤ a₃?          a₁ ≤ a₃?
           /      \          /      \
         是        否      是        否
         /          \      /          \
    [1,2,3]     a₁ ≤ a₃? [2,1,3]    a₂ ≤ a₃?
                /      \            /      \
              是        否        是        否
              /          \        /          \
          [1,3,2]    [3,1,2]  [2,3,1]    [3,2,1]
```

**解读**：
- 从根节点开始，问"a₁ ≤ a₂?"
- 如果是，走左边；如果否，走右边
- 继续比较，直到到达叶节点
- 叶节点 [1,2,3] 表示排序结果：a₁ ≤ a₂ ≤ a₃

#### 大白话理解决策树

想象你玩一个"猜排序"游戏：

```text
你要给3个人按身高排序：小明、小红、小刚
你只能问"是/否"问题，比如：
- "小明比小红高吗？"
- "小红比小刚高吗？"
```

**决策树就是把这个"问问题"的过程画成一棵树：**

- **每个圆圈（内部节点）**：问一个问题（比较两个数）
- **往左走**：回答"是"
- **往右走**：回答"否"
- **最底下的方框（叶节点）**：得到最终排序结果

**为什么要用决策树？** 因为它能把排序算法的"思考过程"可视化，让我们能数清楚：最坏情况下到底要问多少个问题（比较多少次）。

### 7.3 关键观察

**观察1：叶节点数 ≥ n!**

n个不同的数有 **n!** 种可能的排列。排序算法必须能够区分所有这些情况，因此：

$$
\text{叶节点数} \geq n!
$$

**例如**：3个数有 3! = 6 种排列，上图恰好有6个叶节点。

**观察2：树的深度决定比较次数**

- 从根到叶的路径长度 = 该情况下的比较次数
- 树的**深度 h** = 最坏情况下的比较次数
- 因此，算法的最坏时间复杂度 = **O(h)**

**观察3：二叉树深度与叶节点数的关系**

深度为 h 的二叉树，最多有 2^h 个叶节点：

$$
\text{叶节点数} \leq 2^h
$$

#### 大白话理解这三个观察

**观察1 的直觉：每种排列都要有"归宿"**

排序的本质是把乱序的数"归位"。比如 3 个数 [a, b, c]，最终可能的结果有 6 种：
```text
[a,b,c]  [a,c,b]  [b,a,c]  [b,c,a]  [c,a,b]  [c,b,a]
```

每个叶节点代表一种排序结果。如果你的决策树只有 5 个叶节点，那就有一种排列"没地方去"——算法就不完整了！

**打个比方**：想象你是快递分拣员，有 6 个不同的包裹要放进 6 个不同的格子。你的分拣流程图（决策树）**至少要有 6 个终点**，否则总有包裹找不到归宿。

---

**观察2 的直觉：走的路越长，问的问题越多**

```text
                第1次比较
               /        \
          第2次比较    第2次比较
           /    \       /    \
         ...   ...   ...    ...
```

- 从根走到叶：每经过一个节点，就做一次比较
- 路径长度 = 比较次数
- 树的深度 h = 最长的那条路径 = **最坏情况**

**打个比方**：想象你在玩"20个问题"猜物品的游戏。有些物品 5 个问题就猜到（短路径），有些要 15 个问题（长路径）。最坏情况 = 最难猜的那个物品需要的问题数。

---

**观察3 的直觉：二叉树每层最多翻倍**

```text
深度 0（根）: 1 个节点
深度 1:      最多 2 个节点
深度 2:      最多 4 个节点
深度 3:      最多 8 个节点
...
深度 h:      最多 2^h 个节点
```

每往下一层，节点数最多**翻倍**（因为每个节点最多有 2 个孩子）。

**反过来想**：如果你需要装下 n! 个叶节点，树至少要多深？答案是 h ≥ log₂(n!)。

---

**三个观察串起来**：

```text
观察1: 叶节点 ≥ n!        （排序结果有这么多种）
          ↓
观察3: 2^h ≥ 叶节点 ≥ n!  （二叉树的数学性质）
          ↓
       h ≥ log(n!)        （取对数）
          ↓
观察2: 深度 h = 最坏比较次数
          ↓
       最坏比较次数 ≥ log(n!) = Ω(n log n)
```

**这就是为什么比较排序逃不过 O(n log n) 的根本原因！**

### 7.4 下界推导

结合上述观察：

$$
n! \leq \text{叶节点数} \leq 2^h
$$

因此：

$$
2^h \geq n!
$$

两边取对数：

$$
h \geq \log_2(n!)
$$

**关键问题**：log(n!) 是多少？

#### 斯特林公式（Stirling's Approximation）

$$
n! \approx \sqrt{2\pi n} \left(\frac{n}{e}\right)^n
$$

取对数：

$$
\log(n!) = n\log n - n\log e + O(\log n) = \Theta(n \log n)
$$

**简化证明**（不用斯特林公式）：

$$
\log(n!) = \log(1 \cdot 2 \cdot 3 \cdots n) = \sum_{i=1}^{n} \log i
$$

下界估计（只取后半部分）：

$$
\log(n!) \geq \sum_{i=n/2}^{n} \log i \geq \frac{n}{2} \cdot \log\frac{n}{2} = \frac{n}{2}(\log n - 1)
$$

因此：

$$
\log(n!) \geq \frac{n \log n}{2} - \frac{n}{2} = \Omega(n \log n)
$$

#### 大白话理解：log(n!) 为什么等于 Θ(n log n)？

**核心问题**：我们已经知道比较次数 h ≥ log(n!)，但 log(n!) 到底有多大？

---

**方法一：斯特林公式（数学家的工具）**

斯特林公式 n! ≈ √(2πn) × (n/e)^n 是数学家发现的精确近似，你不需要记住它。

取对数后：
```text
log(n!) ≈ log(√(2πn)) + log((n/e)^n)
        ≈ (1/2)log(2πn) + n × log(n/e)
        ≈ O(log n) + n × (log n - log e)
        = n log n - n log e + O(log n)
```

因为 n log n 是最大的那一项，所以 log(n!) = Θ(n log n)。

---

**方法二：简化证明（更直观！）**

不想用斯特林公式？没问题！我们用更朴素的方法。

**第一步：把 log(n!) 展开**

根据对数性质，乘法变加法：
```text
log(n!) = log(1 × 2 × 3 × ... × n)
        = log1 + log2 + log3 + ... + log n
```

**第二步：只看"后半部分"来估计下界**

这是一个聪明的技巧——我们只算从 n/2 到 n 这一段：
```text
log(n!) = log1 + log2 + ... + log(n/2) + log(n/2+1) + ... + log(n)
          └────── 前半部分（扔掉） ──────┘└────── 后半部分（只看这个） ──────┘
```

后半部分有 **n/2 项**，每一项至少是 **log(n/2)**，所以：
```text
log(n!) ≥ (n/2) × log(n/2) = (n/2) × (log n - 1) = (n log n)/2 - n/2
```

**第三步：得出结论**

当 n 很大时，(n log n)/2 远大于 n/2，所以 log(n!) = Ω(n log n)。

---

**用具体数字感受一下（n = 8）**：

```text
log(8!) = log1 + log2 + log3 + log4 + log5 + log6 + log7 + log8
        = 0 + 1 + 1.58 + 2 + 2.32 + 2.58 + 2.81 + 3
        = 15.29

后半部分（从4到8）= 2 + 2.32 + 2.58 + 2.81 + 3 = 12.71

下界估计：(n/2) × log(n/2) = 4 × log4 = 4 × 2 = 8

实际 15.29 ≥ 估计 8 ✓
```

---

**两种方法的对比**：

| 方法 | 优点 | 缺点 |
| ---- | ---- | ---- |
| 斯特林公式 | 精确，能得到常数项 | 需要记住公式 |
| 简化证明 | 直观，不需要公式 | 只能得到下界 |

两种方法殊途同归，都证明了 **log(n!) = Θ(n log n)**！

### 7.5 定理总结

> **定理 1.2**（排序下界定理）
>
> 以比较两个数为基础的排序算法，最坏情况的时间复杂度**下界**为 **Ω(n log n)**。

**证明要点回顾**：

```text
1. 决策树深度 h = 最坏比较次数

2. 叶节点数 ≥ n!（覆盖所有排列）

3. 2^h ≥ 叶节点数 ≥ n!

4. h ≥ log(n!) = Ω(n log n)

5. 因此最坏时间复杂度 ≥ Ω(n log n)
```

#### 大白话总结：推导的因果链

整个证明的逻辑链条可以用一张图概括：

```text
排序必须区分 n! 种排列
        ↓
决策树需要 ≥ n! 个叶节点
        ↓
二叉树深度 h ≥ log(n!)
        ↓
log(n!) = Θ(n log n)
        ↓
最坏情况比较次数 ≥ Ω(n log n)
        ↓
【结论】比较排序不可能比 O(n log n) 更快！
```

#### 用具体数字感受一下

**排序10个数：**
- 排列数 = 10! = 3,628,800（超过360万种可能）
- 决策树至少需要 log₂(3,628,800) ≈ 22 层深度
- 而 10 × log₂(10) ≈ 33

所以即使只有10个数，最坏情况下也需要比较20多次。随着 n 增大，比较次数以 **n log n** 的速度增长，这是逃不掉的！

### 7.6 重要推论

**推论1**：归并排序和堆排序是**渐近最优**的比较排序算法。

**推论2**：如果要突破 O(n log n)，必须**不基于比较**，例如：

| 算法 | 时间复杂度 | 原理 |
| ---- | ---- | ---- |
| 计数排序 | O(n + k) | 利用数值范围有限 |
| 基数排序 | O(d(n + k)) | 按位排序 |
| 桶排序 | O(n) 平均 | 数据均匀分布假设 |

这些算法通过**额外假设**（如数值范围、分布特性）绕过了比较排序的下界限制。

### 7.7 与网格生成的联系

在计算几何和网格生成中，很多算法涉及排序：

- **Delaunay三角剖分**：需要对点按坐标排序
- **扫描线算法**：需要对事件点排序
- **凸包算法**：需要对点按角度排序

这些算法的复杂度下界也受 O(n log n) 约束，这就是为什么很多计算几何算法的最优复杂度是 **O(n log n)**。

### 7.8 决策树证明：三句话速记

> **第一句**：排序 n 个数有 n! 种可能结果，决策树必须有 n! 个叶节点来区分它们。
>
> **第二句**：深度为 h 的二叉树最多 2^h 个叶节点，所以 h ≥ log(n!)。
>
> **第三句**：log(n!) = Θ(n log n)，因此比较排序的下界就是 O(n log n)，不可能更快了！

---

## 参考资料

1. Knuth, D. E. "Big Omicron and big Omega and big Theta." ACM Sigact News, 1976.
2. Cormen, T. H., et al. "Introduction to Algorithms." MIT Press.
3. 欧拉公式与平面图性质：任意图论教材的基础章节
4. 《计算几何及应用》第1.2.2节：排序时间复杂度的下界
